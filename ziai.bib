@comment{{This file has been generated by bib2bib 1.97}}

@comment{{Command line: /usr/bin/bib2bib -s year -r -oc ziai-citations -ob ziai.bib -c 'author : "Ziai"' -c 'year > 2008' /home/rziai/bibs/icall.bib}}

@misc{Wall.Ott.ea-14,
  author = {Albert Wall and Niels Ott and Ramon Ziai and Bj\"orn Rudzewitz},
  title = {Macuna\'ima as a Data Source for the Distribution and Interpretation
	of Bare {NPs} in {B}razilian {P}ortuegese: Corpus preparation and
	first Annotation Agreement Results},
  howpublished = {Poster at the Third International Conference on Ibero-Romance Historical
	Corpora (CODILI 3)},
  month = {6},
  year = {2014},
  address = {Zurich, Switzerland},
  owner = {nott},
  timestamp = {2014.06.27},
  url = {http://drni.de/zap/wall-ott-ea-14-poster}
}

@inproceedings{Ziai.Meurers-14,
  author = {Ramon Ziai and Detmar Meurers},
  title = {Focus Annotation in Reading Comprehension Data},
  booktitle = {Proceedings of the 8th Linguistic Annotation Workshop (LAW VIII, 2014)},
  year = {2014},
  address = {Dublin, Ireland},
  organization = {COLING},
  publisher = {Association for Computational Linguistics},
  note = {To appear},
  url = {http://purl.org/dm/papers/Ziai.Meurers-14.html}
}

@inproceedings{Ott.Ziai.ea-13,
  author = {Niels Ott and Ramon Ziai and Michael Hahn and Detmar Meurers},
  title = {{CoMeT}: Integrating different levels of linguistic modeling for
	meaning assessment},
  booktitle = {Proceedings of the 7th International Workshop on Semantic Evaluation
	(SemEval)},
  year = {2013},
  pages = {608--616},
  address = {Atlanta, GA, USA},
  file = {:Ott.Ziai.ea-13.pdf:PDF},
  pdf = {Http://aclweb.org/anthology/S13-2102.pdf},
  url = {http://purl.org/dm/papers/Ott.Ziai.ea-13.html}
}

@inproceedings{Ziai.Ott.ea-12a,
  author = {Ramon Ziai and Niels Ott and Detmar Meurers},
  title = {Short Answer Assessment: Establishing Links Between Research Strands},
  booktitle = {{Proceedings of the 7th Workshop on Innovative Use of {NLP} for {B}uilding
	{E}ducational {A}pplications (BEA-7) at {NAACL-HLT} 2012}},
  year = {2012},
  pages = {190--200},
  address = {Montreal},
  abstract = {A number of different research subfields are concerned with the automatic
	assessment of student answers to comprehension questions, from language
	learning contexts to computer science exams. They share the need
	to evaluate free-text answers but differ in task setting and grading/evaluation
	criteria, among others. This paper has the intention of fostering
	synergy between the different research strands. It discusses the
	different research strands, details the crucial differences, and
	explores under which circumstances systems can be compared given
	publicly available data. To that end, we present results with the
	CoMiC-EN Content Assessment system (Meurers et al., 2011a) on the
	dataset published by Mohler et al. (2011) and outline what was necessary
	to perform this comparison. We conclude with a general discussion
	on comparability and evaluation of short answer assessment systems.},
  crossref = {bea-12},
  keywords = {rte recognizing textual entailment meaning comparison comic cosec
	automatic grading scoring weblas carmeltc c-rater oxford content
	assessment module cam bachman rose leacock chodorow mitchell pulman
	sukkarieh perez makatchev vanlehn bailey evaluation kappa gold standard
	kappa correlation},
  optpublisher = {Association for Computational Linguistics},
  url = {http://aclweb.org/anthology/W12-2022.pdf}
}

@incollection{Ott.Ziai.Meurers-12,
  author = {Ott, Niels and Ziai, Ramon and Meurers, Detmar},
  title = {Creation and Analysis of a Reading Comprehension Exercise Corpus:
	Towards Evaluating Meaning in Context},
  booktitle = {Multilingual Corpora and Multilingual Corpus Analysis},
  publisher = {Benjamins},
  year = {2012},
  editor = {Thomas Schmidt and Kai W\"{o}rner},
  series = {Hamburg Studies in Multilingualism (HSM)},
  pages = {47--69},
  address = {Amsterdam},
  url = {http://purl.org/dm/papers/ott-ziai-meurers-12.html}
}

@misc{Ziai.Ott.ea-12,
  author = {Ramon Ziai and Niels Ott and Detmar Meurers},
  title = {Evaluating Answers to Reading Comprehension Questions in Context},
  howpublished = {Poster at the 2012 Annual Conference of {Deutsche} {Gesellschaft}
	f\"ur {Sprachwissenschaft} ({DGfS})},
  month = {3},
  year = {2012},
  address = {Frankfurt am Main, Germany},
  file = {:Ziai.Ott.ea-12-poster.pdf:PDF;Ziai.Ott.ea-12.pdf:Ziai.Ott.ea-12.pdf:PDF},
  owner = {nott},
  timestamp = {2012.03.12},
  url = {http://drni.de/zap/ziai-ott-ea-12-poster}
}

@proceedings{bea-12,
  title = {Proceedings of the 7th Workshop on Innovative Use of {NLP} for Building
	Educational Applications ({BEA7}) at {NAACL-HLT}},
  year = {2012},
  editor = {Joel Tetreault and Jill Burstein and Claudial Leacock},
  address = {Montr√©al, Canada},
  publisher = {Association for Computational Linguistics},
  month = {June},
  booktitle = {Proceedings of the 7th Workshop on Innovative Use of {NLP} for Building
	Educational Applications ({BEA7}) at {NAACL-HLT}},
  comment = {cf. naacl-hlt-12},
  owner = {mzepf},
  timestamp = {2012.05.23}
}

@article{Amaral.Meurers.Ziai-10,
  author = {Luiz Amaral and Detmar Meurers and Ramon Ziai},
  title = {Analyzing Learner Language: Towards A Flexible {NLP} Architecture
	for Intelligent Language Tutors},
  journal = {Computer-Assisted Language Learning},
  year = {2011},
  volume = {24},
  pages = {1--16},
  number = {1},
  file = {Amaral.Meurers.Ziai-10.pdf:Amaral.Meurers.Ziai-10.pdf:PDF},
  owner = {rziai},
  timestamp = {2010.04.09},
  url = {http://purl.org/dm/papers/amaral-meurers-ziai-10.html}
}

@article{Meurers.Ziai.ea-11,
  author = {Detmar Meurers and Ramon Ziai and Niels Ott and Stacey Bailey},
  title = {Integrating Parallel Analysis Modules to Evaluate the Meaning of
	Answers to Reading Comprehension Questions},
  journal = {IJCEELL. Special Issue on Automatic Free-text Evaluation},
  year = {2011},
  volume = {21},
  pages = {355--369},
  number = {4},
  editor = {Jos\'{e} Antonio Le\'{o}n and Diana P\'{e}rez-Mar\'{i}n},
  publisher = {Inderscience Publishers},
  timestamp = {2010.11.24},
  url = {http://purl.org/dm/papers/meurers-ziai-ott-bailey-11.html}
}

@inproceedings{Meurers.Ziai.ea-11b,
  author = {Detmar Meurers and Ramon Ziai and Niels Ott and Janina Kopp},
  title = {Evaluating Answers to Reading Comprehension Questions in Context:
	Results for German and the Role of Information Structure},
  booktitle = {Proceedings of the TextInfer 2011 Workshop on Textual Entailment},
  year = {2011},
  pages = {1--9},
  address = {Edinburgh, Scotland, UK},
  month = {July},
  publisher = {Association for Computational Linguistics},
  file = {Meurers.Ziai.ea-11b.pdf:Meurers.Ziai.ea-11b.pdf:PDF},
  owner = {nott},
  timestamp = {2011.06.10},
  url = {http://aclweb.org/anthology/W11-2401}
}

@incollection{Widmann.Kohn.ea-11,
  author = {Johannes Widmann and Kurt Kohn and Ramon Ziai},
  title = {The {SACODEYL} search tool -- exploiting corpora for language learning
	purposes},
  booktitle = {New Trends in Corpora and Language Learning},
  publisher = {Continuum International Publishing Group},
  year = {2011},
  editor = {Ana Frankenberg-Garcia and Lynne Flowerdew and Guy Aston},
  volume = {14},
  series = {Corpora and Discourse},
  chapter = {10},
  pages = {167--178},
  address = {London and New York},
  owner = {rziai},
  timestamp = {2011.05.27}
}

@inproceedings{Meurers.Ott.ea-10,
  author = {Detmar Meurers and Niels Ott and Ramon Ziai},
  title = {Compiling a Task-Based Corpus for the Analysis of Learner Language
	in Context},
  booktitle = {Pre-Proceedings of Linguistic Evidence},
  year = {2010},
  pages = {214--217},
  address = {T\"{u}bingen},
  abstract = {Corpora in linguistics and computational linguistics have traditionally
	been assembled from data sources such as newspaper texts, books and,
	more recently, the web. While these sources provide large quantities
	of language data, typically very little or nothing is known about
	the context under which the text has been produced. The only information
	an analysis can refer to is the text itself, e.g., when a sentence
	is analyzed using the preceding sentences for disambiguation. However,
	language is always produced in a concrete extra-linguistic context.
	This contextual setting includes world knowledge and situational
	knowledge, i.e., the aspects of world knowledge which are relevant
	to interpret the given text and the concrete task and situation that
	the language was produced for. The notion of a task and the evaluation
	of language in context plays a particularly important role in foreign
	language teaching and learning (cf., e.g., Ellis 2003) and a representation
	of the learner's ability to use language in context and to perform
	tasks using appropriate task strategies has been argued to be crucial
	for learner modeling (Amaral and Meurers 2008). However, the so-called
	learner corpora created to document the language produced by language
	learners typically consist only of learner essays. In this paper,
	we present our efforts at collecting a longitudinal learner corpus
	consisting of the answers to reading comprehension questions, including
	an explicit representation of the task context and learner information.
	After introducing the data sources and characteristics of the corpus
	we are collecting, we discuss the development of the open-source
	WELCOME tool, which we have created to facilitate the interdisciplinary
	exchange of the contextualized learner corpus between the language
	programs providing the data and the computational linguists working
	on its encoding and automatic analysis.},
  file = {Meurers.Ott.ea-10.pdf:Meurers.Ott.ea-10.pdf:PDF},
  owner = {rziai},
  timestamp = {2010.02.25},
  url = {http://purl.org/dm/papers/meurers-ott-ziai-10.html}
}

@inproceedings{Meurers.Ziai.ea-10,
  author = {Detmar Meurers and Ramon Ziai and Luiz Amaral and Adriane Boyd and
	Aleksandar Dimitrov and Vanessa Metcalf and Niels Ott},
  title = {Enhancing Authentic Web Pages for Language Learners},
  booktitle = {{Proceedings of the 5th Workshop on Innovative Use of {NLP} for {B}uilding
	{E}ducational {A}pplications (BEA-5) at {NAACL-HLT} 2010}},
  year = {2010},
  pages = {10--18},
  address = {Los Angeles},
  publisher = {Association for Computational Linguistics},
  url = {http://aclweb.org/anthology/W10-1002.pdf}
}

@inproceedings{Ott.Ziai-10,
  author = {Niels Ott and Ramon Ziai},
  title = {Evaluating Dependency Parsing Performance on {G}erman Learner Language},
  booktitle = {Proceedings of the Ninth International Workshop on Treebanks and
	Linguistic Theories},
  year = {2010},
  editor = {Markus Dickinson and Kaili M\"{u}\"{u}risep and Marco Passarotti},
  volume = {9},
  series = {NEALT Proceeding Series},
  pages = {175--186},
  file = {Ott.Ziai-10.pdf:Ott.Ziai-10.pdf:PDF},
  owner = {rziai},
  timestamp = {2010.10.18},
  url = {http://hdl.handle.net/10062/15960}
}

@mastersthesis{Ziai-09,
  author = {Ramon Ziai},
  title = {{A Flexible Annotation-Based Architecture for Intelligent Language
	Tutoring Systems}},
  school = {Universit\"{a}t T\"{u}bingen, Seminar f\"{u}r Sprachwissenschaft},
  year = {2009},
  month = {April},
  abstract = {This thesis presents a general architecture for Intelligent Language
	Tutoring Systems. The architecture makes use of annotation-based
	processing to encode different linguistic information at deep and
	shallow levels in a flexible manner and associate it with the learner
	input string. At the same time, it leaves the original input untouched,
	which is different from traditional pipeline approaches used in other
	Intelligent Computer-Assisted Language Learning systems. We show
	that this is necessary in order for feedback to be both error-specific
	and useful to the learner. Furthermore, the architecture incorporates
	a general mechanism for the use of activity models in guiding processing
	and feedback. The approach uses error types as a means of formulating
	pedagogical goals of individual activities. These error types are
	then mapped to analysis requirements that can be used to adapt processing
	of the learner input to the activity. More importantly, error types
	are used to influence the feedback strategy towards the errors that
	a particular activity centers on. We also demonstrate a similar use
	of error counts in the learner model to guide feedback. We have evaluated
	the system on the basis of example scenarios. They show that we are
	indeed able to give more useful feedback than the baseline system
	TAGARELA (Amaral, 2007) in a number of cases. This is the result
	of both annotation-based processing and integration of activity and
	learner model into the feedback process.},
  file = {Ziai-09.pdf:Ziai-09.pdf:PDF},
  owner = {rziai},
  timestamp = {2009.07.23},
  url = {http://www.sfs.uni-tuebingen.de/~rziai/papers/Ziai-09.pdf}
}

